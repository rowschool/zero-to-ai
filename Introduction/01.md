# Day 1

In today's lesson:
- calculate and apply regression analysis to datasets
- understand the difference between linear and non-linear data
- understand how to quantify and validate linear models
- understand how to apply scaling and normalization as part of the data processing step in machine learning

We'll go over:
- scikit-learn
- regression analysis

1. Create a model.
2. Fit (train) the model to the data.
3. Use the model to make predictions.

There is usually no single "right" algorithm - instead, experimentation and validation is key.

## Instructor Do: Univariate Linear Regression

Linear regression is a fundamental algorithm in machine learning.
It is used as a building block for other ML models.
It is easy to understand, calculate and interpret.
It is fast!
It is often good enough. Don't over-engineer your solution.
If your data is linear, then use a linear model.

### What is linear data?

```
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.datasets import make_regression

X, y = make_regression(n_samples=20, n_features=1, random_state=0, noise=4, bias=100.0)
plt.scatter(X, y)

https://imgur.com/qfkIu05
```

The response or output is directly proportional to the input.
We can see from the data that we have a linear trend in our model.
We can use Linear Regression to fit a line through the data.

https://imgur.com/4TA4ryl

Using a trained model allows us to make predictions of the output value (Home Selling Price) given a new input (Number of Bathrooms).

https://imgur.com/XYacgqR

If we get a new house on the market:

https://imgur.com/m8Q8KKc

We can use our linear model to predict the price of that house.

https://imgur.com/1iIBMeM

### What about non-linear data?

```
from sklearn.datasets import make_s_curve

data, color = make_s_curve(100, random_state=0)
plt.scatter(data[:,0], color)
```

https://imgur.com/EHn3DsG

### Linear Regression

A regression line is simply calculating a line that best fits the data. This is typically done through the least squares method where the line is chosen to have the smallest overall distance to the points.

y = &theta;<sub>0</sub> + &theta;<sub>1</sub>x

- y is the output response
- x is the input feature
- &theta;<sub>0</sub> is the y-axis intercept
- &theta;<sub>1</sub> is the weight coefficient (slope)

### Sklearn

The Sklearn library provides us with a Linear Regression model that will fit a line to our data. Sklearn follows a consistent API where you define a model object, fit the model to the data, and then make predictions with the model.

```
from sklearn.linear_model import LinearRegression

# create the model
model = LinearRegression()

# fit the model to our data
model.fit(X, y)

# the _ suffix means the attribute is available after the model is fit to the data (trained)
model.coef_ # weight coefficients
model.intercept_ # y-axis intercept

# Our linear model is now of the form:
# y = 101.90 + 12.44x

# we can use our model to make predictions
predictions = model.predict(X)

y[0] # true output
predictions[0] # predicted output
predictions[0] - y[0] # prediction error

pd.DataFrame({"Predicted": predictions, "Actual": y, "Error": predictions - y})[["Predicted", "Actual", "Error"]]

| --- | Predicted | Actual | Error |
...
```

We can calculate the output response for the minimum and maximum input values.
Note: This is useful later when we want to plot the fit line.

x_min = X.min()
x_max = X.max()

y_min_actual = y.min() # actual min value
y_max_actual = y.max() # actual max value

y_min = 101.90 + 12.44 * x_min # calculated min value
y_max = 101.90 + 12.44 * x_max # calculated max value

We can also use the predict function to calculate predicted values.

y_min_predicted = model.predict(x_min) # predicted min value
y_max_predicted = model.predict(x_max) # predicted max value

We can show the model fit by plotting the predicted values against the original data.

plt.scatter(X, y, c="blue")
plt.plot([x_min, x_max], [y_min, y_max], c="red")

https://imgur.com/aEAS0zs

## Students Do: Univariate Linear Regression

### Dataset:  lsd.csv

Source: Wagner, Agahajanian, and Bing (1968). Correlation of Performance
Test Scores with Tissue Concentration of Lysergic Acid Diethylamide in
Human Subjects. Clinical Pharmacology and Therapeutics, Vol.9 pp635-638.

Description: Group of volunteers was given LSD, their mean scores on
math exam and tissue concentrations of LSD were obtained at n=7 time points.

Variables/Columns

TC: Tissue Concentration   1-4
SCORE: Math Score          8-12

```
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Read the csv file into a pandas dataframe
lsd = pd.read_csv("../Resources/lsd.csv")
lsd.head()

# Assign the data to X and y
# Note: Sklearn requires a 7 x 1 array of values
# So we use reshape(-1, 1) to create this
# This is only necessary for a 1D array
X = lsd.tc.values.reshape(-1, 1)
y = lsd.score.values.reshape(-1, 1)

print("Shape: ", X.shape, y.shape)
X

# Plot the data
# YOUR CODE HERE
plt.scatter(X, y)

# Create the model and fit the model to the data
from sklearn.linear_model import LinearRegression
# YOUR CODE HERE
model = LinearRegression()

# Fit the model to the data
# Note: This is the training step where you fit the line to the data.
# YOUR CODE HERE
model.fit(X, y)

# Print the coefficient and the intercept for the model
# YOUR CODE HERE
model.coef_
model.intercept_

# Note: We have to transform our min and max values so they are in the format: array([[ 1.17 ]])
# This is the required format for model.predict()
x_min = np.array([[X.min()]])
x_max = np.array([[X.max()]])

# Calculate the y_min and y_max using model.predict and x_min and x_max
# YOUR CODE HERE
y_min = model.predict(x_min)
y_max = model.predict(x_max)

# Plot X and y using plt.scatter
# Plot the model fit line using [x_min[0], x_max[0], y_min[0], y_max[0]]
# YOUR CODE HERE
plt.scatter(X, y, c="blue")
plt.plot([x_min[0], x_max[0]], [y_min[0], y_max[0]], c="red")
```

Once you master the Model, Fit, Predict steps, it's easier to switch to other ML models.

## Instructor Do: Quantifying Regression

We're going to show the importance of validation by splitting data into training and testing sets.

We'll slice 80% of our data to use as part of our training set.
We'll use the other 20% to predict values for our testing set.

1. Fit (Train) the model.
We can predict our output by using the training data to fit the model to the data.
This is the training step where we predict our output using a given set of features.
Once the model is trained, we can use it to make predictions.

2. Test the trained model.
We can use the test data to make new predictions.
We can compare this actual output to our predictions made by the model.
We can calculate an accuracy score for the model.

3. We can use the model for predicting if the R^2 or Mean Squared Error are within a certain range of desired values.

```
# import dependencies
from sklearn.datasets import make_regression
from sklearn.linear_model import LinearRegression

# generate some data
X, y = make_regression(n_samples=20, n_features=1, random_state=0, noise=4, bias=100.0)

# create a linear model
model = LinearRegression()

# fit (train) the model to the data
model.fit(X, y)
```

# Quantifying our model (MSE or R^2 score)

There are a variety of ways to quantify our model.

from sklearn.metrics import mean_squared_error, r2_score

```
# use our model to predict a value
predicted = model.predict(X)

# score the prediction with MSE and R^2
mse = mean_squared_error(y, predicted) # 11.93
r2 = r2_score(y, predicted) # 0.90

A "good" MSE score will be close to zero while a "good" R2 score will be close to 1.
R2 is the default scoring for many of the Sklearn models.

# overall score for the model
model.score(X, y) # 0.90
```

# Validation

We also want to understand how well our model performs on new data.
One approach for this is to split your data into a training and testing dataset.
You fit (train) the model using training data, and score and validate your model using the testing data.
This train/test splitting is so common that Sklearn provides a mechanism for doing this.

# Testing and Training Data

In order to quantify our model against new input values, we often split the data into training and testing data.
The model is then fit to the training data and scored by test data.
Sklearn pre-processing provides a library for automatically splitting up the data into training and testing.

```
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# train the model using the training data
model.fit(X_train, y_train)

# score the model using the unseen testing data
model.score(X_test, y_test) # 0.92
```

TODO: Notes
https://github.com/coding-boot-camp/DataViz-Lesson-Plans/blob/Scramble-Branch/01-Lesson-Plans/21-Machine-Learning/1/LessonPlan.md#05-instructor-do-quantifying-regression-010
